---
title: "Final Report: Your Title Here"
author: "Don Francisco"
date: "December 5, 2018"
output:
    github_document: default
bibliography: references.bib
csl: bioinformatics.csl
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Add about 2-3 pages here. Across the whole manuscript, you should cite at least 20 peer reviewed articles.

# Methods

## Study design

Add about half a page here. In this section instead of first person (I/we), use the authors of the paper you selected, since you'll just be describing what they did, based on the methods in their paper.

## Sample origin and sequencing

Add about half a page here. In this section instead of first person (I/we), use the authors of the paper you selected, since you'll just be describing what they did, based on the methods in their paper.

## Computational

These are the methods you used to do your bioinformatic analyses analyses. Should probably be between 0.5 and 1 pages. At a very minimum should include citations for DADA2 and phyloseq if you are doing an amplicon study, or other citations as appropriate.

# Results

## Subsections are ok in the results section too

```{r your-code-here}
# Add code chunks as needed for your analyses
# For most analyses, I would recommend splitting the
# intensive computational part into a seperate R script file
# and then just load your libraries and the data object here
# using the `load()` function. Ask me for clarification if this is
# unclear.
```
                    


```{r}
# load-packages-and-data
# load general-use packages
library("dplyr")
library("tidyr")
library("knitr")
library("ggplot2")
library("tibble")

# this package allows for the easy inclusion of literature citations in our Rmd
# more info here: https://github.com/crsh/citr
# and here:
# http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
library("citr")

# These are the primary packages well use to clean and analyze the data
# this package needs to be installed from bioconductor -- it's not on CRAN
# see info here: https://benjjneb.github.io/dada2/dada-installation.html
library("dada2")

# This to export a fasta of our final denoised sequence variants
library("seqinr")

# To install this you have to install from GitHub
# See more info here: https://github.com/leffj/mctoolsr
# run this -- install.packages("devtools")
# and then this -- devtools::install_github("leffj/mctoolsr")
library("mctoolsr")

# And this to visualize our results
# it also needs to be installed from bioconductor
library("phyloseq")

```


```{r extract-sample-and-file-names}
# NOTE: Much of the following follows the DADA2 tutorials available here:
# https://benjjneb.github.io/dada2/tutorial.html
# Accessed October 19, 2017
# set the base path for our input data files
path <- "data/raw_data"

# Sort ensures samples are in order
filenames_forward_reads <- sort(list.files(path, pattern = ".fastq"))

# Extract sample names, assuming filenames have format: SAMPLENAME.fastq
sample_names <- sapply(strsplit(filenames_forward_reads, "\\."), `[`, 1)

# Specify the full path to each of the filenames_forward_reads
filenames_forward_reads <- file.path(path, filenames_forward_reads)


# check-quality-plots
# Plots the quality profiles of all twenty samples
# 1:2 numbers of sequence read
plotQualityProfile(filenames_forward_reads[1:5])


# filter-reads
# Place filtered files in filtered/ subdirectory
# note this will fail if the directory doesn't exist
filter_path <- file.path("output", "filtered")
filtered_reads_path <- file.path(filter_path,
                                 paste0(sample_names,
                                        "_filt.fastq.gz"))
# See ?filterAndTrim for details on the parameters
# See here for adjustments for 454 data:
# https://benjjneb.github.io/dada2/
#     faq.html#can-i-use-dada2-with-my-454-or-ion-torrent-data
filtered_output <- filterAndTrim(fwd = filenames_forward_reads,
                                 filt = filtered_reads_path,
                                 maxLen = 300,
                                 maxN = 0, # discard any seqs with Ns
                                 maxEE = 3, # allow w/ up to 3 expected errors
                                 truncQ = 2, # cut off if quality gets this low
                                 rm.phix = TRUE,
                                 compress = TRUE,
                                 multithread = TRUE)



# filtered-read-counts-table
# produce nicely-formatted markdown table of read counts
# before/after trimming
kable(filtered_output,
      col.names = c("Reads In",
                    "Reads Out"))
```


```{r}
# learn-errors
# this build error models from each of the samples
errors_forward_reads <- learnErrors(filtered_reads_path,
                                 multithread = TRUE)


# visualize-errors-with-plots
# quick check to see if error models match data
# (black lines match black points) and are generally decresing left to right
plotErrors(errors_forward_reads,
           nominalQ = TRUE)

```

```{r}
# dereplicate-sequences
# get rid of any duplicated sequences
dereplicated_forward_reads <- derepFastq(filtered_reads_path,
                                         verbose = TRUE)
# Name the derep-class objects by the sample names
names(dereplicated_forward_reads) <- sample_names
```

```{r}
# make-sequence-table
# produce the 'site by species matrix'
sequence_table <- makeSequenceTable(dada_forward_reads)


# histogram-of-sequence-lengths
# Quick check to look at distribution of trimmed and denoised sequences
hist(nchar(getSequences(sequence_table)),
     main = "Histogram of final sequence variant lengths",
     xlab = "Sequence length in bp")


# remove-chimeras
# Check for and remove chimeras
sequence_table_nochim <- removeBimeraDenovo(sequence_table,
                                            method = "consensus",
                                            multithread = FALSE,
                                            verbose = TRUE)
# What percent of our reads are non-chimeric?
non_chimeric_reads <- round(sum(sequence_table_nochim) / sum(sequence_table),
                            digits = 4) * 100
```


```{r}
# table-of-pipeline-read-counts
# Build a table showing how many sequences remain at each step of the pipeline
get_n <- function(x) sum(getUniques(x)) # make a quick function
track <- cbind(filtered_output, # already has 2 columns
               sapply(dada_forward_reads, get_n),
               rowSums(sequence_table),
               rowSums(sequence_table_nochim))
# add nice meaningful column names
colnames(track) <- c("Input",
                     "Filtered",
                     "Denoised",
                     "Sequence Table",
                     "Non-chimeric")
# set the proper rownames
rownames(track) <- sample_names
# produce nice markdown table of progress through the pipeline
kable(track)


# assign-taxonomy
# assigns taxonomy to each sequence variant based on a supplied training set
# made up of known sequences
taxa <- assignTaxonomy(sequence_table_nochim,
                       "data/training/rdp_train_set_16.fa.gz",
                       multithread = FALSE,
                       tryRC = TRUE) # also check with seq reverse compliments
# show the results of the taxonomy assignment
unname(taxa)
```

```{r}
# extract-sequences-to-fasta
# we want to export the cleaned, trimmed, filtered, denoised sequence variants
# so that we can build a phylogeny - we'll build the phylogeny outside of R
# but we need the fasta file to do so. We keep the names of each sequence as the
# sequence itself (which is rather confusing), because that's how DADA2 labels
# it's columns (e.g. 'species')
# function taken from https://github.com/benjjneb/dada2/issues/88
export_taxa_table_and_seqs <- function(sequence_table_nochim,
                                       file_seqtab,
                                       file_seqs) {
  seqtab_t <- as.data.frame(t(sequence_table_nochim)) # transpose to data frame
  seqs <- row.names(seqtab_t) # extract rownames
  row.names(seqtab_t) <- seqs # set rownames to sequences
  outlist <- list(data_loaded = seqtab_t)
  mctoolsr::export_taxa_table(outlist, file_seqtab) # write out an OTU table
  seqs <- as.list(seqs)
  seqinr::write.fasta(seqs, row.names(seqtab_t), file_seqs) # write out fasta
}
# actually run the function, with the names of the files we want it to create
# and where to put them
export_taxa_table_and_seqs(sequence_table_nochim,
                           "output/sequence_variants_table.txt",
                           "output/sequence_variants_seqs.fa")

```

```{r}
# read-in-metadata-and-create-phyloseq
# Next we want to read in the metadata file so we can add that in too
# This is not a csv file, so we have to use a slightly different syntax
# here the `sep = "\t"` tells the function that the data are tab-delimited
# and the `stringsAsFactors = FALSE` tells it not to assume that things are
# categorical variables
metadata_in <- read.csv("data/metadata/EDRN_MIMARKS_.csv",
                        row.names = 1,
                        na.strings = "not provided",
                        stringsAsFactors = FALSE) # sets sample IDs to row names


metadata_in$tot_height.cm. <- gsub(pattern = "\\s",
                                   replacement = "",
                                   metadata_in$tot_height.cm.,
                                   perl = TRUE)
metadata_in$tot_mass.kg. <- gsub(pattern = "\\s",
                                   replacement = "",
                                   metadata_in$tot_mass.kg.,
                                   perl = TRUE)

metadata_in$tot_height.cm. <- as.numeric(metadata_in$tot_height.cm.)
metadata_in$tot_mass.kg. <- as.numeric(metadata_in$tot_mass.kg.)

metadata_in_bmi <- metadata_in %>%
  rownames_to_column() %>%
  mutate(bmi = tot_mass.kg. / ((tot_height.cm. / 100) ^2 )) 

print(metadata_in_bmi, digits = 2)

metadata_in_bmi$tot_height.cm. <- as.factor(metadata_in_bmi$tot_height.cm.)
metadata_in_bmi$tot_mass.kg. <- as.factor(metadata_in_bmi$tot_mass.kg.)
metadata_in_bmi$bmi <- as.factor(metadata_in_bmi$bmi)

metadata_in_final <- metadata_in_bmi %>%
  column_to_rownames() 


# Check the row names in each of the files
row.names(metadata_in_bmi)
row.names(sequence_table_nochim)

old_row_names <- row.names(sequence_table_nochim)
new_row_names <- sapply(strsplit(old_row_names, "_"), `[`, 1)

# check that new_row_names is what we want before running the last line of code
# we want it to be the same as the metadata table row names
new_row_names

# then assign the new names to the row names
row.names(sequence_table_nochim) <- new_row_names

# Construct phyloseq object (straightforward from dada2 outputs)
phyloseq_obj <- phyloseq(otu_table(sequence_table_nochim,
                                   taxa_are_rows = FALSE), # sample-spp matrix
                         sample_data(metadata_in_final),# metadata for each sample
                         tax_table(taxa)) # taxonomy for each sequence variant


melted_obj <- psmelt(phyloseq_obj)

save(phyloseq_obj, file = "output/phyloseq_obj.Rdata")
save(melted_obj, file = "output/melted_obj.Rdata")

```


```{r}
melted_obj <- psmelt(phyloseq_obj)
```








```{r FOBT-Phylum-disease-corrolation-barplot}
# To examine the difference of microbia composition
# under the context of Phylum, in different tissue
# types and FOBT results
melted_obj %>%
  ggplot(aes(x = disease_stat,
             y = Abundance,
             fill = Phylum,
             color = Phylum)) +
  geom_col(position = "dodge")
```
Figure 1. In different types of tissue samples, they have very similar composition of microbia communities, but there are differences in the sbunance of different phlyum. The distribution pattern in three kinds of tisssue samples are very different. The Bacteroidetes abundance decreased in adenoma and carcinoma tissues. 


```{r top-Phylum-into-class-and-FOBT-barplot}
# Take the most commonly found Phylums from previous figure
# examine the class under them, and in different tissue types
# and FOBT results

melted_obj %>%
  filter(Phylum %in% c("Proteobacteria", "Fusobacteria", "Firmicutes", "Bacteroidetes", "Lentisphaerae")) %>%
  filter(Class != "NA") %>%
  ggplot(aes(x = Class,
             y = Abundance,
             color = FOBT.result,
             fill = FOBT.result)) +
  geom_col(position = "dodge") +
  facet_grid(~ disease_stat) +
  theme(axis.text.x = element_text(angle = 90,
                                     hjust = 1))
```
Figure 2. Picked out top five most Phylum that has a diffrent zbundance in cancer tissue than the normal tissue. Then aexamine their corrolation between Class and FOBT results. Blood clots were only found in cancer tissues, and cancer tissue has a different micorbia community distribution than the normal tissue. There are several class high significant high abundance in the FOBT positive cacner tissues. 

```{r class-tissue-sex-barplot}
# Take the Classes that are highly found in adenoma and carcinoma tissue
# which are FOBT positive. Examine how aundance different in different genders
melted_obj %>%
  filter(Class %in% c("Gammaproteobacteria", "Bacilli", "Bacteroidia", 
                      "Clostridia", "Negativicutes", "Fusobacteriia")) %>%
  filter(FOBT.result == "positive") %>%
  ggplot(aes(x = disease_stat,
             y = Abundance,
             fill = Class,
             color = Class)) +
  geom_col() +
  facet_grid(~ sex)
```

Figure 3. Filtered out the Class that in significantly more abundant in FOBT positive cancer tissues. Then examine the distribution of the Classes in both FOBT status and the tissue types. There is a higher abunadance of microbia community than FOBT negative tissues. Specifically, in the 





```{r Clostridia-Bacteroidia-sex-Family-barplot}
# For tissues that has blood clot in,
# what are the Family found under Class Clostridia and Bacteroidia
# and their relationships with gender and cancer types

melted_obj %>%
  filter(Class %in% c("Clostridia", "Bacteroidia")) %>%
  filter(FOBT.result == "positive") %>%
  filter(Family != "NA") %>%
  ggplot(aes(x = disease_stat,
             y = Abundance,
             fill = Family,
             color = Family)) +
  geom_col(position = "dodge") +
  facet_grid(~ sex)
```
Figure 4. In both male and female, FOBT positive admona and carcinoma tissues, there are several bacteria Family is commonly found. In addition to those male has a more diversed microbia community and higher abundancy. 

```{r Genus-tissuetypes-FOBT-barplot}
# Taken the bacteria Family that is commonly found above
# and exame the Genus found under them, also the relationship
# between cancer type and FOBT 

melted_obj %>%
  filter(Family %in% c("Lachnospiraceae", "Ruminococcaceae", "Bacteroidaceae")) %>%
  filter(Genus != "NA") %>%
  ggplot(aes(x = disease_stat,
             y = Abundance,
             fill = Genus,
             color = Genus)) +
  geom_col(position = "dodge") +
  facet_grid(~ FOBT.result) +
  theme(axis.text.x = element_text(angle = 90,
                                     hjust = 0.1))
```
Figuer 5. Taken the commnly found Families from previous graph, examine their Genus distribution in all tissues types, both FOBT postive and negative. In the FOBT positive tissues, there is a in gernal lowering of the microbial abundance. But there is a consistancy in the patterns of the community composition. *Oscillibacter* is the Genus that is found significantly more in FOBT negative tissue than the FOBT positive tissue.



```{r Oscillibacter-FOBTneg-loc-barplot}
# From the FOBT negative tissues, how Oscillibacter is 
# distributed along with different bmi and location

melted_obj %>%
  filter(Genus %in% c("Oscillibacter")) %>%
  filter(FOBT.result == "negative") %>%
  ggplot(aes(x = as.numeric(as.character(bmi)),
             y = Abundance,
             color = geo_loc_name,
             fill = geo_loc_name)) +
  geom_col(position = "dodge") +
  facet_grid(~ disease_stat) +
  theme(axis.text.x = element_text(angle = 90,
                                     hjust = 0.1))
```
 



In addition to a minimum of 5-8 figures/tables (and associated captions), you should include sufficient text in this section to describe what your findings were. Remember that in the results section you just describe what you found, but you don't interpret it - that happens in the discussion. 2-3 pages.

# Discussion

Add around 3-4 pages interpreting your results and considering future directions one might take in analyzing these data.

# Sources Cited
